[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi I’m Mark - a scientist turned full stack engineer, living in Edinburgh, Scotland.\nThis blog will feature: Insights from data, Building software in public, Experiences with tools and workflows and Escapades in husbandary (being a husband not cultivating plants/animals), fatherhood, sport/fitness and food.\nThe photo is from this years Loch Ness 24, a 24 hour run that I completed with a few friends. That was me on lap 4 of 8, sodden, in a stinking tent - it marked my last happy lap!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Blog 2.0",
    "section": "",
    "text": "I used to blog for years but it slowly tailed off.\nI miss having a place on the internet where I can put down ideas, progress on side projects and general life stuff. So here it is - blog 2.0.\nMainly what you’ll get here is:\n\nInsights from data\nBuilding software in public\nExperiences with tools and workflows\nEscapades in husbandary (being a husband not cultivating plants/animals), fatherhood, sport/fitness and food.\n\nI’ve always been fond of authors that try to make their work reproducible and I will attempt that too for the data/software stuff, time permitting.\nThat’s enough of a welcome, now onto the first post.\n\n\n\nby Shubham Dhage"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "The ERA5 tour (part 1)\n\n\n\n\n\n\ndata\n\n\n\n\n\n\n\n\n\nSep 10, 2024\n\n\nMark Cherrie\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 2.0\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 10, 2024\n\n\nMark Cherrie\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/era5tour/index.html",
    "href": "posts/era5tour/index.html",
    "title": "The ERA5 tour (part 1)",
    "section": "",
    "text": "marko swift\nERA5 deserves the same recognition as Miss Swift IMO."
  },
  {
    "objectID": "posts/era5tour/index.html#so-what-is-era5",
    "href": "posts/era5tour/index.html#so-what-is-era5",
    "title": "The ERA5 tour (part 1)",
    "section": "So what is ERA5?",
    "text": "So what is ERA5?\nERA5 is short for ECMWF Reanalysis v5 and is a climate data product from the Copernicus Climate Change Service (C3S) at the European Centre for Medium-Range Weather Forecasts (ECMWF). It’s a picture of past weather using a wide range of data sources via numerical weather prediction (NWP) models. OK, enough acronyms for now.\nThe main WOW factor that ERA5 has over other datasets is it’s incredible spatial and temporal resolution. The data begins 4 months into World War 2 (January 1940) and goes to present day, for every hour, for every 31km section of land and sea across the globe.\nIn terms of the climate data there is a wide selection at a single atmospheric level and a few at multi-level (e.g. pressure, temperature). Popular single level data includes:\n\n10m u-component of wind (velocity in the East direction)\n10m v-component of wind (velocity in the North direction)\nMean wave period\nSignificant height of combined wind waves and swell\n2m temperature\nTotal precipitation"
  },
  {
    "objectID": "posts/era5tour/index.html#what-would-you-want-to-do-with-this-data",
    "href": "posts/era5tour/index.html#what-would-you-want-to-do-with-this-data",
    "title": "The ERA5 tour",
    "section": "What would you want to do with this data?",
    "text": "What would you want to do with this data?\nThere are so many potential applications of this data from renewable energy project development (link) to public health."
  },
  {
    "objectID": "posts/era5tour/index.html#how-do-you-access-this-data",
    "href": "posts/era5tour/index.html#how-do-you-access-this-data",
    "title": "The ERA5 tour (part 1)",
    "section": "How do you access this data?",
    "text": "How do you access this data?\nThere are three main ways to access the data that I know about:\n\nClimate Data Store - Copernicus API (CDS API)\nS3 storage (GCP/AWS)\nGoogle Earth Engine (GEE)\n\n\n\n\nFigure 1: Sources of ERA5 data\n\n\nDeciding on which source you use depends on how much data you need and what variables you need. If you need less than a year of any variable go for CDS API; if you need more than a year and any variable email for a bulk download; if you need over a year for a selection of variables then you might be able to use data on AWS/GCP. The Google Earth Engine option can do both, but comes at a high cost for commercial applications; there’s also a good python-based tutorial here.\nIn the next couple sections I will explain how to obtain credentials, make a request for a portion of ERA5 data and then process in python.\n\nCDS API\nThe standard way to interact with ERA5 data and one that does a great job for smaller datasets (most likely less than a year).\n\nCredentials\nCreate an account on cds - go to this page - follow the instructions and create the $HOME/.cdsapirc file.\n\n\nData Request\nFrom here you want to generate the API request, the website will build this for you if use the select boxes :\n\nNow copy and paste that into a python script - this will download the data into a netcdf called “download.nc”:\n\nimport cdsapi\n\nc = cdsapi.Client()\n\nc.retrieve(\n    'reanalysis-era5-single-levels',\n    {\n        'product_type': 'reanalysis',\n        'format': 'netcdf',\n        'year': '2024',\n        'month': '09',\n        'variable': [\n            '10m_u_component_of_wind', '10m_v_component_of_wind',\n        ],\n        'day': [\n            '01', '02', '03',\n            '04', '05',\n        ],\n        'time': [\n            '00:00', '01:00', '02:00',\n            '03:00', '04:00', '05:00',\n            '06:00', '07:00', '08:00',\n            '09:00', '10:00', '11:00',\n            '12:00', '13:00', '14:00',\n            '15:00', '16:00', '17:00',\n            '18:00', '19:00', '20:00',\n            '21:00', '22:00', '23:00',\n        ],\n        'anon_user_timestamp': '2024-09-11 08:09:06',\n    },\n    'download.nc')\n\n\n\nProcessing\nDownload HDF5 libraries for your Linux distribution, then pip install the netCDF4 package.\n\nimport netCDF4 as nc\n\n# Open the NetCDF file\nfile_path = 'download.nc'\ndataset = nc.Dataset(file_path, 'r')\n\n# Print the dataset information\nprint(dataset)\n\n# Extract a variable (e.g., temperature)\ntemperature = dataset.variables['temperature'][:]\n\n# Print the variable information\nprint(temperature)\n\n# Close the dataset\ndataset.close()\n\n\n\n\nAnalysis-Ready, Cloud Optimized ERA5 (hosted on GCP)\n////////// insert some details /////////\n\nCredentials\nThe data is public so no need for credentials.\n\n\nData Request\nPip install the xarray, zarr, fsspe and gcsfs packages.\nFollow the tutorial.\n\n\nProcessing\nThe data is in Zarr format…. advantages etc.\n\n\n\nERA5 forcing data for the Weather Research and Forecasting (WRF) model (hosted on AWS)\nGlobal timeseries at 0.25 degree resolution from 2000-01 onwards in CSV format, for four variables:\n\n100-m wind speed\n100-m wind direction\n2-m temperature\nsurface pressure\n\n\nCredentials\nIt’s a public bucket again, so no credentials needed, however you need to either add configuration details to ~/.aws/credentials or add config as the following way when creating the S3 client:\n\nfrom botocore import UNSIGNED\nfrom botocore.client import Config\nimport boto3\n\ns3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n\n\n\nData request\nFollow this tutorial. In summary you want to find the gid (1 to 1038240) that matched with the latitude/longitude pair that you are interested in and then use this code:\n\nimport pandas as pd\nfrom io import StringIO\n\n# example GID\ngid = \"1038240\"\n\n# Define the S3 bucket and file path\nbucket_name = 'era5-for-wrf'\nfile_key = f'global_single_level/cells/{gid}/timeseries.csv'\n\n# Get the file object\ns3_object = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n\n# Read the file content\nfile_content = s3_object['Body'].read().decode('utf-8')\n\n# Use StringIO to convert the file content to a file-like object\ncsv_string_io = StringIO(file_content)\n\n# Read the CSV file into a Pandas DataFrame\nera5_df = pd.read_csv(csv_string_io, index_col = 0, skiprows = 1, parse_dates = True)\n\n\n\nProcessing\nThe data per point is a CSV with datetime as the index and then the four variables above, simple to work with in pandas or whatever data package you want to use."
  },
  {
    "objectID": "posts/era5tour/index.html#why-is-this-a-timely-blog-post",
    "href": "posts/era5tour/index.html#why-is-this-a-timely-blog-post",
    "title": "The ERA5 tour (part 1)",
    "section": "Why is this a timely blog post?",
    "text": "Why is this a timely blog post?\nThis instance of the CDS will be decommissioned on 26 September 2024 and will no longer be accessible from this date onwards. Please check our informative page to migrate to CDS-Beta now"
  },
  {
    "objectID": "posts/era5tour/index.html#what-can-you-do-with-this-data",
    "href": "posts/era5tour/index.html#what-can-you-do-with-this-data",
    "title": "The ERA5 tour (part 1)",
    "section": "What can you do with this data?",
    "text": "What can you do with this data?\nThere are so many potential applications of this data from weather impacts on renewable energy project development (link) and public health, alongside the more standard meterological questions of assessing flood risk, climate change etc."
  },
  {
    "objectID": "posts/era5tour/index.html#what-next",
    "href": "posts/era5tour/index.html#what-next",
    "title": "The ERA5 tour (part 1)",
    "section": "What next?",
    "text": "What next?\nERA6 will have some advances over ERA5, including improvements:\n\nresolution of at least 18 km,\nmodel bias,\nrealism of near-surface quantities,\nocean wave physics\n\n… but won’t be available until 2027. So there’s still life in ERA5 for some time yet, but some things are changing.\nThe current instance of CDS API will be decommissioned on 26 September 2024 and will no longer be accessible from this date onwards.\nPart 2 of this blog will summarise how to get access via the new CDS route."
  }
]