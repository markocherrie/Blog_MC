[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi I’m Mark - a scientist turned full stack engineer, living in Edinburgh, Scotland.\nThis blog will feature: Insights from data, Building software in public, Experiences with tools and workflows and Escapades in husbandary (being a husband not cultivating plants/animals), fatherhood, sport/fitness and food.\nThe photo is from this years Loch Ness 24, a 24 hour run that I completed with a few friends. That was me on lap 4 of 8, sodden, in a stinking tent - it marked my last happy lap!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Blog 2.0",
    "section": "",
    "text": "I used to blog for years but it slowly tailed off.\nI miss having a place on the internet where I can put down ideas, progress on side projects and general life stuff. So here it is - blog 2.0.\nMainly what you’ll get here is:\n\nInsights from data\nBuilding software in public\nExperiences with tools and workflows\nEscapades in husbandary (being a husband not cultivating plants/animals), fatherhood, sport/fitness and food.\n\nI’ve always been fond of authors that try to make their work reproducible and I will attempt that too for the data/software stuff, time permitting.\nThat’s enough of a welcome, now onto the first post.\n\n\n\nby Shubham Dhage"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "The ERA5 tour (part 1)\n\n\n\n\n\n\ndata\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nMark Cherrie\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 2.0\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 10, 2024\n\n\nMark Cherrie\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/era5tour/index.html",
    "href": "posts/era5tour/index.html",
    "title": "The ERA5 tour (part 1)",
    "section": "",
    "text": "ERA5 deserves the same recognition as Miss Swift IMO"
  },
  {
    "objectID": "posts/era5tour/index.html#so-what-is-era5",
    "href": "posts/era5tour/index.html#so-what-is-era5",
    "title": "The ERA5 tour (part 1)",
    "section": "So what is ERA5?",
    "text": "So what is ERA5?\nERA5 is short for ECMWF Reanalysis v5 and is a climate data product from the Copernicus Climate Change Service (C3S) at the European Centre for Medium-Range Weather Forecasts (ECMWF). It’s a picture of past weather using a wide range of data sources via numerical weather prediction (NWP) models. OK, enough acronyms for now.\nThe main WOW factor that ERA5 has over other datasets is it’s incredible spatial and temporal resolution. The data begins 4 months into World War 2 (January 1940) and goes to present day, for every hour, for every 31km section of land and sea across the globe.\nIn terms of the climate data there is a wide selection at a single atmospheric level and a few at multi-level (e.g. pressure, temperature). Popular single level data includes:\n\n10m u-component of wind (velocity in the East direction)\n10m v-component of wind (velocity in the North direction)\nMean wave period\nSignificant height of combined wind waves and swell\n2m temperature\nTotal precipitation"
  },
  {
    "objectID": "posts/era5tour/index.html#what-would-you-want-to-do-with-this-data",
    "href": "posts/era5tour/index.html#what-would-you-want-to-do-with-this-data",
    "title": "The ERA5 tour",
    "section": "What would you want to do with this data?",
    "text": "What would you want to do with this data?\nThere are so many potential applications of this data from renewable energy project development (link) to public health."
  },
  {
    "objectID": "posts/era5tour/index.html#how-do-you-access-this-data",
    "href": "posts/era5tour/index.html#how-do-you-access-this-data",
    "title": "The ERA5 tour (part 1)",
    "section": "How do you access this data?",
    "text": "How do you access this data?\nThere are four main ways to access the data that I know about:\n\nClimate Data Store - Copernicus API (CDS API)\nAnalysis-Ready, Cloud Optimized ERA5 (hosted on GCP)\nERA5 forcing data for the Weather Research and Forecasting (WRF) model (hosted on AWS)\nGoogle Earth Engine (GEE)\n\n\n\n\nFigure 1: Sources of ERA5 data\n\n\nDeciding on which source you use depends on how much data you need and what variables you need. If you need less than a year of any variable go for CDS API; if you need more than a year and any variable then you could try to arrange a bulk download with CDS; if you need over a year for a selection of variables then you might be able to use data on AWS/GCP. The Google Earth Engine option can do both, but comes at a high cost for commercial applications; if you are working in a university and already familiar with GEE then a good python-based tutorial is available here.\nIn the next couple sections I will summarise and signpost to resources on setting up your working environment, making a request for a portion of ERA5 data and then processing in python.\n\nCDS API\nThe CDS API is the standard way to interact with ERA5 data and one that does a great job for smaller datasets (most likely less than a year).\n\nSetup\nCreate an account on CDS by going to this page - follow the instructions and create the $HOME/.cdsapirc file. Pip install cdsapi.\nTo work with the outputs you might need to download HDF5 libraries (for me on mac it was ‘brew install hdf5’). Once that’s set up pip install the netCDF4 package.\n\n\nData Request\nFrom here you want to generate the API request, the website will build this for you if use the select boxes, see below for my wonderful clicking and scrolling skills :\n\nNow copy and paste that into a python script - this will download the data into a netcdf called “download.nc”:\n\n\nShow the code\nimport cdsapi\n\nc = cdsapi.Client()\n\nc.retrieve(\n    'reanalysis-era5-single-levels',\n    {\n        'product_type': 'reanalysis',\n        'format': 'netcdf',\n        'year': '2024',\n        'month': '09',\n        'variable': [\n            '10m_u_component_of_wind', '10m_v_component_of_wind',\n        ],\n        'day': [\n            '01', '02', '03',\n            '04', '05',\n        ],\n        'time': [\n            '00:00', '01:00', '02:00',\n            '03:00', '04:00', '05:00',\n            '06:00', '07:00', '08:00',\n            '09:00', '10:00', '11:00',\n            '12:00', '13:00', '14:00',\n            '15:00', '16:00', '17:00',\n            '18:00', '19:00', '20:00',\n            '21:00', '22:00', '23:00',\n        ],\n        'anon_user_timestamp': '2024-09-11 08:09:06',\n    },\n    'download.nc')\n\n\n\n\nProcessing\nThe data is netcdf - a common file type for multidimensional array data. When I say multidimensional, what I’m generally thinking of is 4 dimensions - latitude, longitude, time and some interesting data. A key feature of netcdf is that metadata is embedded within the file. When you print the dataset in python you will get to see all this useful information like the projection.\nHere is an example of working with the netcdf file:\n\n\nShow the code\nimport netCDF4 as nc\n\n# Open the NetCDF file\nfile_path = 'download.nc'\ndataset = nc.Dataset(file_path, 'r')\n\n# Print the dataset information\nprint(dataset)\n\n# Extract a variable (e.g., uwind_100)\nuwind_100 = dataset.variables['10m_u_component_of_wind'][:]\n\n# Print the variable information\nprint(uwind_100)\n\n# Close the dataset\ndataset.close()\n\n\n\n\n\nAnalysis-Ready, Cloud Optimized ERA5 (hosted on GCP)\nARCO for short, this has been created by Google to feed into a weather forecasting model. There are five cloud optimised datasets:\n\n‘gcp-public-data-arco-era5/co/model-level-moisture.zarr’,\n‘gcp-public-data-arco-era5/co/model-level-wind.zarr’,\n‘gcp-public-data-arco-era5/co/single-level-forecast.zarr’,\n‘gcp-public-data-arco-era5/co/single-level-reanalysis.zarr’,\n‘gcp-public-data-arco-era5/co/single-level-surface.zarr’\n\nThe reanalysis is the one we are interested in.\n\nSetup\nThe data is public so no need for credentials.\nPip install the xarray, zarr, fsspec and gcsfs packages.\n\n\nData Request\nFollow this tutorial.\nOne of the challenging aspects of accessing via this route is that the spatial dimention corresponds to a Gaussian Grid - in particular the reduced Gaussian Grid N320 (which means there are 320 latitude points from the equator to each pole). If you want to subset to a particular lat and long within the Gaussian Grid then you need to use the “GRIB_paramId” attribute, this will related to the values here.\nOtherwise the recommended way is to subset the data using the latitude and longitude attributes. Note that the coordinate system for ERA5 longitudes is 0 to 360 not -180 to 180.\n\n\nProcessing\nZarr is a powerful way to store N-dimensional arrays. The key part is that it is optimised for cloud storage and for parallelised input/output.\nThere’s a bit of a learning curve to working with xarray (and dask) in python but IMO the key concepts are chunks (working on smaller more manageable pieces of data) and tasks (computations to be performed on the chunks). Both chunks and tasks are perfomed lazily so you have to be explicit when you want something to happen (e.g. .compute()) otherwise it will just add to your task graph). By using xarrary and dask you can work with terrabytes of data on your own computer, which is different to the other methods here, which are still constrained by how much you can fit into local memory.\n\n\n\nFigure 2: Zarr format\n\n\n\n\n\nERA5 forcing data for the Weather Research and Forecasting (WRF) model (hosted on AWS)\nThis source is focused on the wind industry. It’s a subset of ERA5 timeseries data at 0.25 degree resolution from 2000-01 onwards in CSV format, for four variables:\n\n100-m wind speed\n100-m wind direction\n2-m temperature\nsurface pressure\n\n\nSetup\nPip install boto3 and pandas.\nIt’s a public bucket again, so no credentials needed, however you need to either add configuration details to ~/.aws/credentials or add config as the following way when creating the S3 client:\n\n\nShow the code\nfrom botocore import UNSIGNED\nfrom botocore.client import Config\nimport boto3\n\ns3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n\n\n\n\nData request\nFollow this tutorial. In summary you want to find the gid (1 to 1038240) that matches with the latitude/longitude pair that you are interested in and then do something similar to below:\n\n\nShow the code\nimport pandas as pd\nfrom io import StringIO\n\n# example GID\ngid = \"1038240\"\n\n# Define the S3 bucket and file path\nbucket_name = 'era5-for-wrf'\nfile_key = f'global_single_level/cells/{gid}/timeseries.csv'\n\n# Get the file object\ns3_object = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n\n# Read the file content\nfile_content = s3_object['Body'].read().decode('utf-8')\n\n# Use StringIO to convert the file content to a file-like object\ncsv_string_io = StringIO(file_content)\n\n# Read the CSV file into a Pandas DataFrame\nera5_df = pd.read_csv(csv_string_io, index_col = 0, skiprows = 1, parse_dates = True)\n\n\n\n\nProcessing\nThe data per point is a CSV with datetime as the index and then the four variables above - simple to work with in pandas or whatever data library you want to use."
  },
  {
    "objectID": "posts/era5tour/index.html#why-is-this-a-timely-blog-post",
    "href": "posts/era5tour/index.html#why-is-this-a-timely-blog-post",
    "title": "The ERA5 tour (part 1)",
    "section": "Why is this a timely blog post?",
    "text": "Why is this a timely blog post?\nThis instance of the CDS will be decommissioned on 26 September 2024 and will no longer be accessible from this date onwards. Please check our informative page to migrate to CDS-Beta now"
  },
  {
    "objectID": "posts/era5tour/index.html#what-can-you-do-with-this-data",
    "href": "posts/era5tour/index.html#what-can-you-do-with-this-data",
    "title": "The ERA5 tour (part 1)",
    "section": "What can you do with this data?",
    "text": "What can you do with this data?\nThere are so many potential applications of this data from wind power simulation and public health, alongside the more standard meterological applications of assessing flood risk, climate change etc."
  },
  {
    "objectID": "posts/era5tour/index.html#what-next",
    "href": "posts/era5tour/index.html#what-next",
    "title": "The ERA5 tour (part 1)",
    "section": "What next?",
    "text": "What next?\nHaving spent the blog post raving about ERA5 you’ll be surprised to hear that their sibling has been planned and will have some major improvements on:\n\nresolution (to at least 18 km),\nmodel bias,\nrealism of near-surface quantities,\nocean wave physics\n\n… so why have I been reading about accessing an inferior data product I hear you say …\nWell, ERA6 is not due until 2027, so there’s still plenty of life in ERA5 for some time yet.\nIn the meantime the current instance of CDS API will be decommissioned on 26 September 2024 and will no longer be accessible from this date onwards so for part 2 of this blog I’ll be updating that part and actually showing you some interesting things that you can do with the data!"
  },
  {
    "objectID": "posts/era5tour/index.html#what-is-era5",
    "href": "posts/era5tour/index.html#what-is-era5",
    "title": "The ERA5 tour (part 1)",
    "section": "What is ERA5?",
    "text": "What is ERA5?\nERA5 is short for ECMWF Reanalysis v5 and is a climate data product from the Copernicus Climate Change Service (C3S) at the European Centre for Medium-Range Weather Forecasts (ECMWF). It’s the best picture of past weather that we have, created using a wide range of data sources via numerical weather prediction (NWP) models. OK, enough acronyms for now.\nThe main WOW factor that ERA5 has over other datasets is it’s incredible spatial and temporal resolution. The data begins 4 months into World War 2 (January 1940) and goes to present day, for every hour, for every 31km section of land and sea across the globe.\nIn terms of the climate data there is a wide selection at a single atmospheric level (i.e. at a specific atmospheric level, e.g. 10 meteres) and a few at multi-level (e.g. pressure, temperature). Popular single level data include:\n\n10m u-component of wind (velocity in the East direction)\n10m v-component of wind (velocity in the North direction)\nMean wave period\nSignificant height of combined wind waves and swell\n2m temperature\nTotal precipitation"
  },
  {
    "objectID": "posts/era5tour/index.html#summary",
    "href": "posts/era5tour/index.html#summary",
    "title": "The ERA5 tour (part 1)",
    "section": "Summary",
    "text": "Summary\nHere is the following spiciness (read difficulty) for accessing each of the data sources:\n\n\n\nTable 1: Data Access Spiciness\n\n\n\n\n\n\n\n\n\n\n\nSource\nSetup\nData Request\nProcessing\n\n\n\n\nCDS API\n\n\n\n\n\nAnalysis-Ready, Cloud Optimized ERA5 (hosted on GCP)\n\n\n\n\n\nERA5 forcing data for the Weather Research and Forecasting (WRF) model (hosted on AWS)"
  }
]